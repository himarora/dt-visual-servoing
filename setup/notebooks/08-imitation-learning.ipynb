{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from utils.helpers import launch_env, wrap_env, view_results_ipython, force_done\n",
    "from utils.helpers import SteeringToWheelVelWrapper, ResizeWrapper, ImgWrapper\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Data from a Teacher\n",
    "\n",
    "In order to use imitation learning in practice, we need to have _demonstrations_. However, demonstrations need to be gathered; in general, we can collect the demonstrations that we need in one of four ways:\n",
    "\n",
    "* Human demonstrator teleoperating the robot\n",
    "* Data logs or historical data\n",
    "* Learned policy (i.e from reinforcement learning) is rolled out\n",
    "* Hard-coded expert is rolled out\n",
    "\n",
    "While these trajectories can be gathered on real robots, to speed up collection, we work mainly in simulation. Duckietown has a [vast](https://logs.duckietown.org) collection of logs gathered over years of running programs on Duckiebots, but here, we focus on the last data collection method: a hard-coded expert.\n",
    "\n",
    "**<font color='red'>Question 1:</font> What are some pros and cons of each approach? List two pros and two cons for each of the four methods listed above.**\n",
    "\n",
    "We first introduce a _pure-pursuit expert_ - often, in robotic imitation learning, we have controllers to control many of our robots and systems; a pure-pursuit expert is about the simplest controller that we can have for a Duckiebot.\n",
    "\n",
    "Our expert drives with ground-truth state data; while more complicated controllers incorporate and fuse observational data to estimate a state, we use data that'd a robot would not normally have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PurePursuitExpert:\n",
    "    def __init__(self, env, ref_velocity=0.04, position_threshold=0.8, gain=10,\n",
    "                 following_distance=0.3, max_iterations=1000):\n",
    "        self.env = env.unwrapped\n",
    "        self.following_distance = following_distance\n",
    "        self.max_iterations = max_iterations\n",
    "        self.ref_velocity = ref_velocity\n",
    "        self.gain = gain\n",
    "        self.position_threshold = position_threshold\n",
    "\n",
    "    def predict(self, observation):  \n",
    "        # Our expert drives with \"cheating\" data, something your implementation will not have access to\n",
    "        closest_point, closest_tangent = self.env.closest_curve_point(self.env.cur_pos, self.env.cur_angle)\n",
    "\n",
    "        iterations = 0\n",
    "        lookup_distance = self.following_distance\n",
    "        curve_point = None\n",
    "        while iterations < self.max_iterations:\n",
    "            # Project a point ahead along the curve tangent,\n",
    "            # then find the closest point to to that\n",
    "            follow_point = closest_point + closest_tangent * lookup_distance\n",
    "            curve_point, _ = self.env.closest_curve_point(follow_point, self.env.cur_angle)\n",
    "\n",
    "            # If we have a valid point on the curve, stop\n",
    "            if curve_point is not None:\n",
    "                break\n",
    "\n",
    "            iterations += 1\n",
    "            lookup_distance *= 0.5\n",
    "\n",
    "        # Compute a normalized vector to the curve point\n",
    "        point_vec = curve_point - self.env.cur_pos\n",
    "        point_vec /= np.linalg.norm(point_vec)\n",
    "\n",
    "        dot = np.dot(self.env.get_right_vec(), point_vec)\n",
    "        steering = self.gain * -dot\n",
    "\n",
    "        return self.ref_velocity, steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_env = launch_env()\n",
    "local_env = wrap_env(local_env)\n",
    "local_env = ResizeWrapper(local_env)\n",
    "local_env = ImgWrapper(local_env)\n",
    "\n",
    "local_env.reset()\n",
    "wrapper = SteeringToWheelVelWrapper()\n",
    "\n",
    "# Create an demonstrator\n",
    "expert = PurePursuitExpert(env=local_env)\n",
    "\n",
    "observations = []\n",
    "actions = []\n",
    "\n",
    "# Collect samples\n",
    "\n",
    "for steps in range(0, nsteps):\n",
    "    # use our 'expert' to predict the next action.\n",
    "    action = expert.predict(None)\n",
    "    action = wrapper.convert(action)\n",
    "    observation, reward, done, info = local_env.step(action)\n",
    "    observations.append(observation)\n",
    "    actions.append(action)\n",
    "\n",
    "    if done:\n",
    "        local_env.reset()\n",
    "        \n",
    "local_env.close()\n",
    "\n",
    "print('\\nDone!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_results_ipython(local_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 2:</font> When you visualize the results, what are two major issues? Play with the expert's code and the execution code above, and list five changes that you tried, as well as their _qualitative_ effects on performance (i.e cover the most distance). DO NOT RESEED THE ENVIRONMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Model\n",
    "\n",
    "While the above expert isn't great, it's a start. What's best is that we now have image `observations` and real-valued `actions` that we can use to train a neural network in Pytorch. Our imitation learner will driver directly from observations, and will be trained with a popular imitation learning loss: Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, action_dim, max_action):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # TODO: You'll need to change this!\n",
    "        flat_size = 0\n",
    "        \n",
    "        ###########################################\n",
    "        # QUESTION 3. What does the next line do? #\n",
    "        ###########################################\n",
    "        self.lr = nn.LeakyReLU()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 8, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 4, stride=2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.dropout = nn.Dropout(.1)\n",
    "\n",
    "        self.lin1 = nn.Linear(flat_size, 100)\n",
    "        self.lin2 = nn.Linear(100, action_dim)\n",
    "\n",
    "        self.max_action = max_action\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.relu(self.conv1(x)))\n",
    "        x = self.bn2(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = self.dropout(x)\n",
    "        x = self.lr(self.lin1(x))\n",
    "\n",
    "        x = self.lin2(x)\n",
    "        x = self.max_action * self.tanh(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training from the Teacher Data\n",
    "\n",
    "We can then write our _training loop_ : the piece of code that implements the process of stochastic gradient descent to minimize the loss between our network's predicted actions and those implemented by our expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 5\n",
    "batchsize = 10\n",
    "\n",
    "actions = np.array(actions)\n",
    "observations = np.array(observations)\n",
    "\n",
    "model = Model(action_dim=2, max_action=1.)\n",
    "model.train().to(device)\n",
    "\n",
    "# weight_decay is L2 regularization, helps avoid overfitting\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.005,\n",
    "    weight_decay=1e-3\n",
    ")\n",
    "\n",
    "avg_loss = 0\n",
    "for epoch in range(nepochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    batch_indices = np.random.randint(0, observations.shape[0], (batchsize))\n",
    "    obs_batch = torch.from_numpy(observations[batch_indices]).float().to(device)\n",
    "    act_batch = torch.from_numpy(actions[batch_indices]).float().to(device)\n",
    "\n",
    "    model_actions = model(obs_batch)\n",
    "\n",
    "    loss = (model_actions - act_batch).norm(2).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss = loss.data.item()\n",
    "    avg_loss = avg_loss * 0.995 + loss * 0.005\n",
    "\n",
    "    print('epoch %d, loss=%.3f' % (epoch, avg_loss))\n",
    "\n",
    "    # Periodically save the trained model\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), 'models/imitate.pt')\n",
    "        \n",
    "print('\\nDone!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 3:</font> Qualitatively explain at least 2 changes you made to both the expert and network (architecture, hyperparameters, episode lengths, number of training episodes / epochs, etc.) (including partial points if we find that you didn't make changes to any part of our code - hyperparameters, network, etc.)**\n",
    "\n",
    "\n",
    "**<font color='red'>Question 4:</font> Explain the issues with the imitation learning loop above. Specifically, comment on the loss function and training objective. Explain at least one issue, and propose a way that could help solve the issues you've brought up.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "force_done(local_env)\n",
    "local_env = launch_env()\n",
    "local_env = wrap_env(local_env)\n",
    "local_env = ResizeWrapper(local_env)\n",
    "local_env = ImgWrapper(local_env)\n",
    "\n",
    "obs = local_env.reset()\n",
    "\n",
    "done = False\n",
    "rewards = []\n",
    "nsteps = 500\n",
    "for steps in range(0, nsteps):\n",
    "    obs = torch.from_numpy(obs).float().to(device).unsqueeze(0)\n",
    "    action = model(obs)\n",
    "    action = action.squeeze().data.cpu().numpy()\n",
    "    obs, reward, done, info = local_env.step(action) \n",
    "    rewards.append(reward)\n",
    "    \n",
    "    if done:\n",
    "        local_env.reset()\n",
    "        print(\"Reset!\")\n",
    "\n",
    "print(info)\n",
    "        \n",
    "local_env.close()\n",
    "\n",
    "\n",
    "print(\"\\nDone!\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_results_ipython(local_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 5:</font> Copy the value of _info_ , after simulating for 500 steps. If your simulation fails earlier, save the results _before_ the failure (i.e. when the simulation returns `done = True`.  DO NOT RESEED THE ENVIRONMENT** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A nastier environment\n",
    "\n",
    "Once your solution is able to pass a curve while staying in the lane, you can try to see what happens if you modify the test environment with respect to the one used to generate the training dataset. \n",
    "\n",
    "To do this, create a new environment called *new_environment* by using the **launch_env()** function as above. This time passing the argument *domain_rand=True*. Basically it randomizes the environment. Once you have the new environment, run again the model without retraining. \n",
    "\n",
    "Then, visualize the results. \n",
    "\n",
    "**<font color='red'>Question 6:</font> Comment the performance of your solution on the new environment, name two reasons that justify the performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run again the agent in the new randomized environment as explained above\n",
    "\n",
    "new_env = launch_env(domain_rand=True)\n",
    "new_env = wrap_env(new_env)\n",
    "new_env = ResizeWrapper(new_env)\n",
    "new_env = ImgWrapper(new_env)\n",
    "\n",
    "obs = new_env.reset()\n",
    "\n",
    "done = False\n",
    "rewards = []\n",
    "nsteps = 300\n",
    "for steps in range(0, nsteps):\n",
    "    obs = torch.from_numpy(obs).float().to(device).unsqueeze(0)\n",
    "    action = model(obs)\n",
    "    action = action.squeeze().data.cpu().numpy()\n",
    "    obs, reward, done, info = new_env.step(action) \n",
    "    rewards.append(reward)\n",
    "    \n",
    "    if done:\n",
    "        new_env.reset()\n",
    "\n",
    "new_env.close()\n",
    "\n",
    "print(\"\\nDone!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualize the results\n",
    "view_results_ipython(new_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
